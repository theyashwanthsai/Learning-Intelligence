# Plan for learning Deep Learning

#### Pre Req
- [x] Daniel Bourke's Course on Pytorch. [Youtube Link](https://youtu.be/Z_ikDlimN6A?si=U2Cjn_yjpvfmvFlV)
- [x] Pick one dataset and do a clean ML workflow on it

### ML Breakthroughs Chronological Implementations

Implementing the most important ML research papers using PyTorch.  
Goal: Read, understand, and implement each paper to deeply learn architectures & training methods.

---

## âœ… Papers to read and implement

#### Foundations Track
- [x] **1958** â€“ Perceptron ([Paper](https://en.wikipedia.org/wiki/Perceptron))
- [x] **1986** â€“ Backpropagation MLP ([Paper](https://www.nature.com/articles/323533a0))
- [x] **1998** â€“ LeNet-5 ([Paper](http://yann.lecun.com/exdb/lenet/))
- [x] **2012** â€“ AlexNet ([Paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf))

#### CNN Track
- [x] **2014** â€“ VGGNet ([Paper](https://arxiv.org/abs/1409.1556))
- [x] **2014** â€“ GoogLeNet / Inception v1 ([Paper](https://arxiv.org/abs/1409.4842))
- [ ] **2015** â€“ ResNet ([Paper](https://arxiv.org/abs/1512.03385))
- [ ] **2016** â€“ DenseNet ([Paper](https://arxiv.org/abs/1608.06993))

#### Sequence + Attention Track
Also, the book by Sebastian Rashcka is too good. Build an LLM from Scratch. Here's my code repository for it: Link [here](https://github.com/theyashwanthsai/tinyLLM)

- [ ] **2013** â€“ Word2Vec ([Paper](https://arxiv.org/abs/1301.3781))
- [x] **2014** â€“ Seq2Seq + Attention ([Paper](https://arxiv.org/abs/1409.0473))
- [x] **2017** â€“ Transformer ([Paper](https://arxiv.org/abs/1706.03762))
- [ ] **2018** â€“ GPT2 Paper ([Paper](https://arxiv.org/abs/1810.04805))

#### Vision Track
- [ ] **2020** â€“ Vision Transformer ([Paper](https://arxiv.org/abs/2010.11929))
- [ ] **2021** â€“ CLIP ([Paper](https://arxiv.org/abs/2103.00020))
- [ ] **2021** â€“ Swin Transformer ([Paper](https://arxiv.org/abs/2103.14030))

#### World Model Track
- [ ] **2018** â€“ World Models ([Paper](https://arxiv.org/abs/1803.10122))
- [ ] **2019** â€“ Dream to Control ([Paper](https://arxiv.org/abs/1912.01603))
- [ ] **2020** â€“ Mastering Atari with Discrete World Models ([Paper](https://arxiv.org/abs/2010.02193))
- [ ] **2023** â€“ Mastering Diverse Domains through Scalable World Models ([Paper](https://arxiv.org/abs/2301.04104))
- [ ] **2024** â€“ Video generation models as world simulators ([Paper](https://openai.com/research/video-generation-models-as-world-simulators))
- [ ] **2024** â€“ Genie: Generative Interactive Environments ([Paper](https://arxiv.org/abs/2402.15391))

#### GAN Track
- [ ] **2014** â€“ GAN ([Paper](https://arxiv.org/abs/1406.2661))
- [ ] **2015** â€“ DCGAN ([Paper](https://arxiv.org/abs/1511.06434))
- [ ] **2017** â€“ Pix2Pix ([Paper](https://arxiv.org/abs/1611.07004))
- [ ] **2020** â€“ DDPM (Diffusion Models) ([Paper](https://arxiv.org/abs/2006.11239))

#### RL Track (Need to add more here)
- [ ] **2013** â€“ DQN ([Paper](https://arxiv.org/abs/1312.5602))
- [ ] **2016** â€“ A3C ([Paper](https://arxiv.org/abs/1602.01783))
- [ ] **2018** â€“ AlphaZero (Mini) ([Paper](https://arxiv.org/abs/1712.01815))

---
If you follow this, youâ€™ll be dangerously good at PyTorch in ~4â€“6 months and youâ€™ll also be fluent in reading & implementing papers, which is a big research skill.

## ðŸ›  How I Work on Each Paper
1. Read abstract & intro.  
2. Understand architecture diagram.  
3. Implement minimal version in PyTorch.  
4. Test on small dataset.  
5. Document learnings in a short note.  

---

## ðŸŽ¯ Goal
- Become fluent in PyTorch by replicating historical breakthroughs.  
- Build a public portfolio of research implementations.  
- Learn to read & implement papers quickly.




